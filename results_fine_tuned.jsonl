{"input": "public class DataProcessor\n{\n    public string ConcatenateStrings(List<string> items)\n    {\n        string result = \"\";\n        foreach (var item in items)\n        {\n            result += item;\n        }\n        return result;\n    }\n}", "output": "This method is CPU-bound due to string concatenation. While this functionality is clear, performance could be improved by using LINQ's Concat method or other more efficient ways to concatenate collections."}
{"input": "public class DatabaseQuery\n{\n    public List<User> GetActiveUsers()\n    {\n        var allUsers = context.Users.ToList();\n        return allUsers.Where(u => u.IsActive).ToList();\n    }\n}", "output": "This method is IO-bound due to database querying. LINQ projection could improve efficiency. Consider caching frequently requested data."}
{"input": "public class SearchAlgorithm\n{\n    public bool FindDuplicate(int[] array1, int[] array2)\n    {\n        foreach (var item1 in array1)\n        {\n            foreach (var item2 in array2)\n            {\n                if (item1 == item2) return true;\n            }\n        }\n        return false;\n    }\n}", "output": "The functionality is clear, but the nested loops could benefit from using LINQ's Contains method or other more efficient ways to perform comparison."}
{"input": "public class FileProcessor\n{\n    public void ProcessLargeFile(string filePath)\n    {\n        string[] lines = File.ReadAllLines(filePath);\n        foreach (string line in lines)\n        {\n            ProcessLine(line);\n        }\n    }\n    private void ProcessLine(string line) { /* processing */ }\n}", "output": "This method is IO-bound due to file reading. Async/await usage helps avoid blocking threads during IO operations."}
{"input": "public class CollectionManager\n{\n    public void AddUniqueItem(List<string> items, string newItem)\n    {\n        if (!items.Contains(newItem))\n        {\n            items.Add(newItem);\n        }\n    }\n}", "output": "This method is CPU-bound due to string comparison and list appending. Input validation should be added to avoid duplicate entries."}
{"input": "public class AsyncHandler\n{\n    public async Task<string> GetDataBlocking(string url)\n    {\n        using var client = new HttpClient();\n        return client.GetStringAsync(url).Result;\n    }\n}", "output": "Async calls are efficient with async/await, but HttpClient should be disposed."}
{"input": "public class DataConverter\n{\n    public List<object> ConvertToObjects(int[] numbers)\n    {\n        var result = new List<object>();\n        foreach (var number in numbers)\n        {\n            result.Add((object)number);\n        }\n        return result;\n    }\n}", "output": "The method is CPU-bound due to computation-heavy foreach loop. Data structure choice could be improved for better memory usage and performance."}
{"input": "public class ExceptionHandler\n{\n    public bool TryParseNumbers(string[] inputs)\n    {\n        foreach (string input in inputs)\n        {\n            try\n            {\n                int.Parse(input);\n            }\n            catch (FormatException)\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n}", "output": "This method is IO-bound due to file reading. Async/await usage helps avoid blocking threads during IO operations."}
{"input": "public class ReflectionProcessor\n{\n    public void ProcessObjects(object[] objects)\n    {\n        foreach (var obj in objects)\n        {\n            var type = obj.GetType();\n            var properties = type.GetProperties();\n            foreach (var prop in properties)\n            {\n                var value = prop.GetValue(obj);\n                Console.WriteLine($\"{prop.Name}: {value}\");\n            }\n        }\n    }\n}", "output": "This method is slow due to reflection. Consider using LINQ or other more efficient ways to query data."}
{"input": "public class RegexProcessor\n{\n    public List<string> ExtractEmails(List<string> texts)\n    {\n        var emails = new List<string>();\n        foreach (var text in texts)\n        {\n            var regex = new Regex(@\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\");\n            var matches = regex.Matches(text);\n            foreach (Match match in matches)\n            {\n                emails.Add(match.Value);\n            }\n        }\n        return emails;\n    }\n}", "output": "This function is IO-bound due to file reading. Async/await usage helps avoid blocking threads during IO operations. Consider using LINQ's File.ReadLines method for more efficient line reading."}
{"input": "public class DictionaryLookup\n{\n    private Dictionary<string, int> _data = new Dictionary<string, int>();\n    \n    public void AddOrUpdate(string key, int value)\n    {\n        if (_data.ContainsKey(key))\n        {\n            _data[key] = value;\n        }\n        else\n        {\n            _data.Add(key, value);\n        }\n    }\n}", "output": "This dictionary is not efficient for looking up values due to its lack of indexing. Consider using a different data structure or implementing functionality to create indexes."}
{"input": "public class SortingAlgorithm\n{\n    public int[] BubbleSort(int[] array)\n    {\n        int n = array.Length;\n        for (int i = 0; i < n - 1; i++)\n        {\n            for (int j = 0; j < n - i - 1; j++)\n            {\n                if (array[j] > array[j + 1])\n                {\n                    int temp = array[j];\n                    array[j] = array[j + 1];\n                    array[j + 1] = temp;\n                }\n            }\n        }\n        return array;\n    }\n}", "output": "This function is CPU-bound due to computation-heavy sorting algorithm. Performance can be improved using more efficient sorting methods or avoiding sorting altogether when order does not matter."}
{"input": "public class XmlProcessor\n{\n    public void ProcessXmlNodes(XmlDocument doc)\n    {\n        foreach (XmlNode node in doc.SelectNodes(\"//item\"))\n        {\n            var childNodes = node.SelectNodes(\".//child\");\n            foreach (XmlNode child in childNodes)\n            {\n                ProcessChild(child);\n            }\n        }\n    }\n    private void ProcessChild(XmlNode child) { /* processing */ }\n}", "output": "This method is CPU-bound due to deep XML node traversal. Async/await usage could improve responsiveness during IO-bound operations."}
{"input": "public class DataAggregator\n{\n    public Dictionary<string, int> CountItems(List<string> items)\n    {\n        var counts = new Dictionary<string, int>();\n        foreach (var item in items)\n        {\n            if (counts.ContainsKey(item))\n                counts[item]++;\n            else\n                counts[item] = 1;\n        }\n        return counts;\n    }\n}", "output": "This method is CPU-bound due to dictionary key enumeration and computation. Input data should be filtered or grouped before counting to avoid performing expensive computations on large datasets. Consider using LINQ's Count() method or other more efficient ways to perform this functionality."}
{"input": "public class TaskProcessor\n{\n    public async Task ProcessTasksSequentially(List<Func<Task>> tasks)\n    {\n        foreach (var task in tasks)\n        {\n            await task();\n        }\n    }\n}", "output": "This method is IO-bound due to async call. Async/await usage helps avoid blocking threads during IO operations."}
{"input": "public class ImageProcessor\n{\n    public void ResizeImages(List<string> imagePaths)\n    {\n        foreach (var path in imagePaths)\n        {\n            using var image = Image.FromFile(path);\n            using var resized = new Bitmap(image, new Size(100, 100));\n            resized.Save(path.Replace(\".jpg\", \"_small.jpg\"));\n        }\n    }\n}", "output": "This method is IO-bound due to file reading and writing. Async/await usage helps avoid blocking threads during IO operations. Consider caching frequently requested files to improve efficiency."}
{"input": "public class CacheManager\n{\n    private List<CacheItem> _cache = new List<CacheItem>();\n    \n    public CacheItem GetItem(string key)\n    {\n        return _cache.FirstOrDefault(x => x.Key == key);\n    }\n    \n    public void AddItem(CacheItem item)\n    {\n        _cache.Add(item);\n    }\n}", "output": "This code is functional but may benefit from caching frequently requested items. Consider implementing caching strategies to improve performance."}
{"input": "public class JsonSerializer\n{\n    public List<T> DeserializeList<T>(List<string> jsonStrings)\n    {\n        var results = new List<T>();\n        foreach (var json in jsonStrings)\n        {\n            var obj = JsonConvert.DeserializeObject<T>(json);\n            results.Add(obj);\n        }\n        return results;\n    }\n}", "output": "This method is IO-bound due to deserialization. Async/await usage could improve responsiveness during deserialization. Consider using JsonNet or other more efficient parsers."}
{"input": "public class NetworkClient\n{\n    public List<string> FetchUrlsSequentially(List<string> urls)\n    {\n        var results = new List<string>();\n        using var client = new HttpClient();\n        foreach (var url in urls)\n        {\n            var response = client.GetStringAsync(url).Result;\n            results.Add(response);\n        }\n        return results;\n    }\n}", "output": "This method is IO-bound due to HTTP requests. Async/await usage helps avoid blocking threads during IO operations. Consider caching frequently requested URLs to improve efficiency."}
{"input": "public class DataValidator\n{\n    public bool ValidateRecords(List<Record> records)\n    {\n        foreach (var record in records)\n        {\n            if (!IsValidRecord(record))\n                return false;\n        }\n        return true;\n    }\n    \n    private bool IsValidRecord(Record record)\n    {\n        return records.Any(r => r.Id != record.Id && r.Email == record.Email);\n    }\n}", "output": "This method is CPU-bound due to computation-heavy record validation. Async/await usage could improve responsiveness during async calls. Consider caching frequently requested data or implementing more efficient ways to validate records."}
{"input": "public class StringManipulator\n{\n    public string RemoveSubstring(string text, string toRemove)\n    {\n        while (text.Contains(toRemove))\n        {\n            text = text.Replace(toRemove, \"\");\n        }\n        return text;\n    }\n}", "output": "This method is CPU-bound due to string manipulation. While this functionality is clear, performance could be improved by using LINQ's Replace method or regular expressions."}
{"input": "public class DataProcessor\n{\n    public List<ProcessedData> ProcessInMemory(List<RawData> data)\n    {\n        var processed = new List<ProcessedData>();\n        var intermediateResults = new List<IntermediateData>();\n        \n        foreach (var item in data)\n        {\n            intermediateResults.Add(Transform(item));\n        }\n        \n        foreach (var intermediate in intermediateResults)\n        {\n            processed.Add(Finalize(intermediate));\n        }\n        \n        return processed;\n    }\n}", "output": "This method is CPU-bound due to computation-heavy processing. Async/await usage helps avoid blocking threads during IO operations, but additional caching or schema design could improve efficiency."}
{"input": "public class EventProcessor\n{\n    public void ProcessEvents(List<Event> events)\n    {\n        var sortedEvents = events.OrderBy(e => e.Timestamp).ToList();\n        foreach (var evt in sortedEvents)\n        {\n            var relatedEvents = events.Where(e => e.CorrelationId == evt.CorrelationId).ToList();\n            ProcessRelatedEvents(relatedEvents);\n        }\n    }\n}", "output": "This method is IO-bound due to database queries. Async/await usage helps avoid blocking threads during IO operations. Sorting and grouping by timestamp could benefit from use of LINQ's OrderBy and GroupBy methods."}
{"input": "public class TreeProcessor\n{\n    public void ProcessTreeRecursive(TreeNode node)\n    {\n        if (node == null) return;\n        \n        ProcessNode(node);\n        \n        foreach (var child in node.Children)\n        {\n            ProcessTreeRecursive(child);\n        }\n    }\n    \n    private void ProcessNode(TreeNode node)\n    {\n        Thread.Sleep(1); // Simulating heavy processing\n    }\n}", "output": "This recursive method is CPU-bound due to deep tree traversal and slow processing per node. Async/await usage could improve responsiveness during IO-bound operations."}
{"input": "public class ConfigurationReader\n{\n    public string GetSetting(string key)\n    {\n        var configFile = File.ReadAllText(\"config.json\");\n        var config = JsonConvert.DeserializeObject<Dictionary<string, string>>(configFile);\n        return config.ContainsKey(key) ? config[key] : null;\n    }\n}", "output": "This method is IO-bound due to file reading. Serialization could be slow due to parsing large JSON files. Consider using more efficient data structures or alternative serialization methods."}
{"input": "public class LogProcessor\n{\n    public void ProcessLogFiles(string[] logPaths)\n    {\n        var allLogs = new List<string>();\n        foreach (var path in logPaths)\n        {\n            allLogs.AddRange(File.ReadAllLines(path));\n        }\n        \n        var errors = allLogs.Where(log => log.Contains(\"ERROR\")).ToList();\n        ProcessErrors(errors);\n    }\n}", "output": "This method is IO-bound due to file reading. Async/await usage helps avoid blocking threads during IO operations. Logging should be efficient to avoid slowing down the application. Consider using log parsing libraries or other more efficient ways to process log files."}
{"input": "public class DataComparison\n{\n    public List<Difference> FindDifferences(List<Record> list1, List<Record> list2)\n    {\n        var differences = new List<Difference>();\n        foreach (var record1 in list1)\n        {\n            var match = list2.FirstOrDefault(r2 => r2.Id == record1.Id);\n            if (match == null || !record1.Equals(match))\n            {\n                differences.Add(new Difference(record1, match));\n            }\n        }\n        return differences;\n    }\n}", "output": "This method is CPU-bound due to computation-heavy equality checking. Async/await usage could improve responsiveness during data comparison. Consider using LINQ's Concat method or other more efficient ways to concatenate collections."}
{"input": "public class DatabaseBulkInsert\n{\n    public void InsertRecords(List<Record> records)\n    {\n        using var connection = new SqlConnection(connectionString);\n        connection.Open();\n        \n        foreach (var record in records)\n        {\n            var command = new SqlCommand(\"INSERT INTO Records VALUES (@id, @name)\", connection);\n            command.Parameters.AddWithValue(\"@id\", record.Id);\n            command.Parameters.AddWithValue(\"@name\", record.Name);\n            command.ExecuteNonQuery();\n        }\n    }\n}", "output": "This code is IO-bound due to database insert calls. Async/await usage helps avoid blocking threads during IO operations. Consider using parameterized queries as shown to avoid SQL injection, but also ensure error handling."}
{"input": "public class MatrixOperations\n{\n    public int[,] MultiplyMatrices(int[,] matrix1, int[,] matrix2)\n    {\n        int rows1 = matrix1.GetLength(0);\n        int cols1 = matrix1.GetLength(1);\n        int cols2 = matrix2.GetLength(1);\n        \n        int[,] result = new int[rows1, cols2];\n        \n        for (int i = 0; i < rows1; i++)\n        {\n            for (int j = 0; j < cols2; j++)\n            {\n                for (int k = 0; k < cols1; k++)\n                {\n                    result[i, j] += matrix1[i, k] * matrix2[k, j];\n                }\n            }\n        }\n        return result;\n    }\n}", "output": "This method is CPU-bound due to computation-heavy matrix multiplication. Performance could be improved using linear algebra libraries or more efficient algorithms."}
{"input": "def process_large_list(items):\n    result = \"\"\n    for item in items:\n        result += str(item) + \",\"\n    return result[:-1]", "output": "This function is CPU-bound due to string concatenation. Performance can be improved by using alternative methods such as joining or concatenating lists."}
{"input": "def find_duplicates(list1, list2):\n    duplicates = []\n    for item1 in list1:\n        for item2 in list2:\n            if item1 == item2:\n                duplicates.append(item1)\n    return duplicates", "output": "This function is CPU-bound due to nested looping and could be optimized using sets or other data structures more suitable for performing comparison operations."}
{"input": "def read_large_file(filename):\n    with open(filename, 'r') as f:\n        content = f.read()\n    lines = content.split('\\n')\n    return [line.strip() for line in lines if line.strip()]", "output": "This function is IO-bound due to file reading. Splitting the file into lines and stripping whitespace improves readability but may impact memory usage and performance due to parsing large files. Consider using alternative methods for processing large files, such as streaming or using more efficient ways to read files."}
{"input": "def check_membership(large_list, item):\n    return item in large_list", "output": "This function is CPU-bound due to list membership checking. Input validation should be added to avoid performance degradation caused by large lists."}
{"input": "import re\n\ndef extract_emails(texts):\n    emails = []\n    for text in texts:\n        pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n        matches = re.findall(pattern, text)\n        emails.extend(matches)\n    return emails", "output": "This function is IO-bound due to regex matching. Consider using alternative methods for parsing email addresses or implementing caching for frequently requested data."}
{"input": "def fibonacci_recursive(n):\n    if n <= 1:\n        return n\n    return fibonacci_recursive(n-1) + fibonacci_recursive(n-2)", "output": "This recursive function is CPU-bound due to computation-heavy Fibonacci calculation and could benefit from memoization or iteration."}
{"input": "def deep_copy_dict(original_dict):\n    import json\n    return json.loads(json.dumps(original_dict))", "output": "This function is deep copying a dictionary, which is slow due to parsing and serializing data. Consider using alternative data structures or methods for deeper copying."}
{"input": "def process_nested_data(data):\n    result = []\n    for outer_item in data:\n        for inner_item in outer_item['items']:\n            for detail in inner_item['details']:\n                if detail['active']:\n                    result.append(detail)\n    return result", "output": "This function is CPU-bound due to deep nested looping. Input data should be processed more efficiently with data structures better suited for storing and querying nested information."}
{"input": "def sort_large_dataset(data):\n    # Bubble sort implementation\n    n = len(data)\n    for i in range(n):\n        for j in range(0, n-i-1):\n            if data[j] > data[j+1]:\n                data[j], data[j+1] = data[j+1], data[j]\n    return data", "output": "This function is CPU-bound due to computation-heavy sorting and could be optimized using more efficient sorting algorithms or other data structures."}
{"input": "def search_in_list(items, target):\n    for i, item in enumerate(items):\n        if item == target:\n            return i\n    return -1", "output": "This function is CPU-bound due to enumeration and comparison. Input validation should be added, and a more efficient way to search for targets should be considered."}
{"input": "def count_occurrences(text, patterns):\n    counts = {}\n    for pattern in patterns:\n        count = 0\n        for i in range(len(text)):\n            if text[i:i+len(pattern)] == pattern:\n                count += 1\n        counts[pattern] = count\n    return counts", "output": "This function is CPU-bound due to string matching. Input data should be pre-processed to reduce matching time, and alternative data structures or algorithms should be considered."}
{"input": "def remove_duplicates_slow(items):\n    unique_items = []\n    for item in items:\n        if item not in unique_items:\n            unique_items.append(item)\n    return unique_items", "output": "This function is slow due to the nested loop and should be optimized using sets or other data structures more suited to storing unique values."}
{"input": "class DataProcessor:\n    def __init__(self):\n        self.cache = []\n    \n    def get_processed_data(self, key):\n        for item in self.cache:\n            if item['key'] == key:\n                return item['value']\n        return None", "output": "This function is IO-bound due to file reading. Cache frequently requested files to improve performance."}
{"input": "def matrix_multiply_naive(matrix1, matrix2):\n    rows1, cols1 = len(matrix1), len(matrix1[0])\n    rows2, cols2 = len(matrix2), len(matrix2[0])\n    \n    result = [[0 for _ in range(cols2)] for _ in range(rows1)]\n    \n    for i in range(rows1):\n        for j in range(cols2):\n            for k in range(cols1):\n                result[i][j] += matrix1[i][k] * matrix2[k][j]\n    \n    return result", "output": "This function is CPU-bound due to computation-heavy matrix multiplication. While the functionality is clear, performance could be improved using numpy or other more efficient ways to perform matrix multiplication."}
{"input": "def parse_data_with_exceptions(data_strings):\n    parsed_data = []\n    for data_str in data_strings:\n        try:\n            parsed = int(data_str)\n            parsed_data.append(parsed)\n        except ValueError:\n            pass\n    return parsed_data", "output": "This function is IO-bound due to parsing data strings. Exception handling helps avoid errors propagating. Consider using regex or other more efficient parsing methods."}
{"input": "def filter_and_transform(data):\n    filtered = []\n    for item in data:\n        if item > 0:\n            filtered.append(item)\n    \n    transformed = []\n    for item in filtered:\n        transformed.append(item * 2)\n    \n    return transformed", "output": "This function is CPU-bound due to computation-heavy filtering and transformation. Input data should be filtered more efficiently, and transformation should be performed on a smaller dataset."}
{"input": "def load_config_repeatedly(config_file):\n    import json\n    settings = {}\n    for i in range(100):\n        with open(config_file, 'r') as f:\n            config = json.load(f)\n            settings.update(config)\n    return settings", "output": "This function is IO-bound due to file reading. JSON parsing could be slow due to deep nesting. Consider using alternative data structures or more efficient parsing methods."}
{"input": "def calculate_distances(points):\n    import math\n    distances = []\n    for i in range(len(points)):\n        for j in range(i+1, len(points)):\n            p1, p2 = points[i], points[j]\n            distance = math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n            distances.append(distance)\n    return distances", "output": "This function is CPU-bound due to computation-heavy square root calculation. Performance could be improved by caching frequently requested distances or using more efficient distance calculation methods."}
{"input": "def merge_dictionaries_slow(dict_list):\n    result = {}\n    for dictionary in dict_list:\n        for key, value in dictionary.items():\n            if key in result:\n                result[key].append(value)\n            else:\n                result[key] = [value]\n    return result", "output": "This function is slow due to deep dictionary merging. Consider using alternative data structures or more efficient merging methods."}
{"input": "def process_xml_slow(xml_string):\n    import xml.etree.ElementTree as ET\n    root = ET.fromstring(xml_string)\n    \n    results = []\n    for element in root.iter():\n        for child in element:\n            if child.tag == 'item':\n                results.append(child.text)\n    return results", "output": "This function is IO-bound due to parsing XML. While this functionality is useful, performance could be improved by using a more efficient XML parser or converting the XML to a different format for easier processing."}
{"input": "def generate_report(data):\n    report = \"\"\n    for item in data:\n        report += f\"ID: {item['id']}, Name: {item['name']}, Status: {item['status']}\\n\"\n    return report", "output": "This function is CPU-bound due to string concatenation. Performance can be improved by using alternative ways to concatenate strings, such as joining lists or using template strings."}
{"input": "def find_common_elements(lists):\n    if not lists:\n        return []\n    \n    common = lists[0]\n    for lst in lists[1:]:\n        new_common = []\n        for item in common:\n            if item in lst:\n                new_common.append(item)\n        common = new_common\n    return common", "output": "This function is CPU-bound due to computation-heavy list intersection. Input validation could improve efficiency. Consider using sets or other data structures more suited to performing intersections."}
{"input": "def validate_emails_slow(email_list):\n    import re\n    valid_emails = []\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    \n    for email in email_list:\n        if re.match(pattern, email):\n            valid_emails.append(email)\n    return valid_emails", "output": "This function is IO-bound due to email validation. Regex matching is slow, especially when dealing with large datasets. Consider using alternative methods for validating emails or implementing caching to improve efficiency."}
{"input": "def aggregate_data_inefficient(records):\n    aggregated = {}\n    for record in records:\n        category = record['category']\n        if category not in aggregated:\n            aggregated[category] = {'sum': 0, 'count': 0}\n        aggregated[category]['sum'] += record['value']\n        aggregated[category]['count'] += 1\n    \n    # Calculate averages inefficiently\n    for category in aggregated:\n        total_sum = aggregated[category]['sum']\n        count = aggregated[category]['count']\n        aggregated[category]['average'] = total_sum / count\n    \n    return aggregated", "output": "This function is CPU-bound due to computation-heavy aggregation. Input data should be filtered and grouped before aggregation to improve efficiency. Consider using pandas or other data frame libraries for more efficient data manipulation."}
{"input": "def search_nested_structures(data, target):\n    found_items = []\n    for item in data:\n        if isinstance(item, dict):\n            for key, value in item.items():\n                if value == target:\n                    found_items.append(item)\n                elif isinstance(value, (list, dict)):\n                    nested_results = search_nested_structures([value], target)\n                    found_items.extend(nested_results)\n        elif isinstance(item, list):\n            nested_results = search_nested_structures(item, target)\n            found_items.extend(nested_results)\n        elif item == target:\n            found_items.append(item)\n    return found_items", "output": "This function is CPU-bound due to deep nested structure evaluation. Performance can be improved by using more efficient ways to iterate over data and avoid deep nesting."}
{"input": "def update_records_one_by_one(database_connection, records):\n    cursor = database_connection.cursor()\n    for record in records:\n        query = f\"UPDATE users SET name='{record['name']}', email='{record['email']}' WHERE id={record['id']}\"\n        cursor.execute(query)\n        database_connection.commit()", "output": "This function is IO-bound due to database queries. While this functionality is clear, updating records one by one could benefit from batch processing or other more efficient ways to update large datasets."}
{"input": "def calculate_statistics_multiple_passes(numbers):\n    total = sum(numbers)\n    count = len(numbers)\n    mean = total / count\n    \n    variance_sum = 0\n    for num in numbers:\n        variance_sum += (num - mean) ** 2\n    variance = variance_sum / count\n    \n    sorted_numbers = sorted(numbers)\n    median = sorted_numbers[len(sorted_numbers) // 2]\n    \n    return {'mean': mean, 'variance': variance, 'median': median}", "output": "This function is CPU-bound due to computation-heavy statistics calculation. Input data should be pre-processed to reduce computation and avoid intermediate result storage. Consider using pandas or NumPy for data processing and matplotlib for plotting."}
{"input": "def process_images_sequentially(image_paths):\n    from PIL import Image\n    processed = []\n    for path in image_paths:\n        img = Image.open(path)\n        resized = img.resize((100, 100))\n        processed.append(resized)\n    return processed", "output": "This function is IO-bound due to file reading and image resizing. Async/await usage helps avoid blocking threads during IO operations. Consider using PIL's Image.open() context manager for better error handling."}
{"input": "function processLargeArray(items) {\n    let result = \"\";\n    for (let i = 0; i < items.length; i++) {\n        result += items[i] + \",\";\n    }\n    return result.slice(0, -1);\n}", "output": "This function is CPU-bound due to array iteration. Performance can be improved using functions, array methods, or other more efficient ways to iterate over arrays."}
{"input": "function findIntersection(arr1, arr2) {\n    const intersection = [];\n    for (let i = 0; i < arr1.length; i++) {\n        for (let j = 0; j < arr2.length; j++) {\n            if (arr1[i] === arr2[j]) {\n                intersection.push(arr1[i]);\n            }\n        }\n    }\n    return intersection;\n}", "output": "The function is performing intersection computation, which is CPU-bound due to nested loops. Input data should be filtered or sorted to improve performance."}
{"input": "function recursiveFibonacci(n) {\n    if (n <= 1) return n;\n    return recursiveFibonacci(n - 1) + recursiveFibonacci(n - 2);\n}", "output": "This recursive function is CPU-bound due to computation-heavy Fibonacci sequence calculation and could benefit from memoization or iteration."}
{"input": "function deepCloneObject(obj) {\n    return JSON.parse(JSON.stringify(obj));\n}", "output": "This function is CPU-bound due to deep cloning of objects. JSON parsing and stringifying are slow due to data typing and structure evaluation. Consider using more efficient ways to deep clone objects, such as lodash's _.cloneDeep() method or manual recursion."}
{"input": "function bubbleSortArray(arr) {\n    const n = arr.length;\n    for (let i = 0; i < n - 1; i++) {\n        for (let j = 0; j < n - i - 1; j++) {\n            if (arr[j] > arr[j + 1]) {\n                [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]];\n            }\n        }\n    }\n    return arr;\n}", "output": "This function is CPU-bound due to computation-heavy sorting. Performance can be improved using more efficient sorting algorithms or avoiding sorting altogether when order does not matter."}
{"input": "function searchLinear(array, target) {\n    for (let i = 0; i < array.length; i++) {\n        if (array[i] === target) {\n            return i;\n        }\n    }\n    return -1;\n}", "output": "This function is CPU-bound due to linear search. Input data should be sorted or otherwise structured to improve efficiency. Consider using square bracket notation or Array.prototype.find() method for better readability."}
{"input": "function removeDuplicatesInefficient(arr) {\n    const unique = [];\n    for (let i = 0; i < arr.length; i++) {\n        if (!unique.includes(arr[i])) {\n            unique.push(arr[i]);\n        }\n    }\n    return unique;\n}", "output": "This function is CPU-bound due to array iteration and comparison. Input validation should be added, and a more efficient way to remove duplicates should be used."}
{"input": "function processNestedData(data) {\n    const result = [];\n    for (const outer of data) {\n        for (const inner of outer.items) {\n            for (const detail of inner.details) {\n                if (detail.active) {\n                    result.push(detail);\n                }\n            }\n        }\n    }\n    return result;\n}", "output": "This function is IO-bound due to data processing. Nested loops could benefit from filtering or other ways to reduce iteration depth. Consider using async/await with data sources or implementing more efficient ways to process large datasets."}
{"input": "function countOccurrences(text, patterns) {\n    const counts = {};\n    for (const pattern of patterns) {\n        let count = 0;\n        for (let i = 0; i <= text.length - pattern.length; i++) {\n            if (text.substr(i, pattern.length) === pattern) {\n                count++;\n            }\n        }\n        counts[pattern] = count;\n    }\n    return counts;\n}", "output": "This function is CPU-bound due to string matching. Input validation should be added, and the function could be optimized using regular expressions or other more efficient ways to match strings."}
{"input": "class InefficientCache {\n    constructor() {\n        this.cache = [];\n    }\n    \n    get(key) {\n        for (const item of this.cache) {\n            if (item.key === key) {\n                return item.value;\n            }\n        }\n        return null;\n    }\n    \n    set(key, value) {\n        this.cache.push({ key, value });\n    }\n}", "output": "This cache function is slow due to linear search. Consider using objects or arrays to store data more efficiently."}
{"input": "function matrixMultiplyNaive(matrix1, matrix2) {\n    const rows1 = matrix1.length;\n    const cols1 = matrix1[0].length;\n    const cols2 = matrix2[0].length;\n    \n    const result = Array(rows1).fill().map(() => Array(cols2).fill(0));\n    \n    for (let i = 0; i < rows1; i++) {\n        for (let j = 0; j < cols2; j++) {\n            for (let k = 0; k < cols1; k++) {\n                result[i][j] += matrix1[i][k] * matrix2[k][j];\n            }\n        }\n    }\n    \n    return result;\n}", "output": "This function is CPU-bound due to computation-heavy matrix multiplication. While the functionality is clear, performance could be improved using more efficient algorithms or leveraging hardware acceleration."}
{"input": "function filterAndTransformInefficient(data) {\n    const filtered = [];\n    for (const item of data) {\n        if (item > 0) {\n            filtered.push(item);\n        }\n    }\n    \n    const transformed = [];\n    for (const item of filtered) {\n        transformed.push(item * 2);\n    }\n    \n    return transformed;\n}", "output": "This function is CPU-bound due to computation-heavy filtering and transformation operations. Input data validation should be added to improve functionality. Async/await usage could improve responsiveness during filtering. Consider using LINQ queries or other more efficient ways to filter and transform data."}
{"input": "function createRegexInLoop(texts, pattern) {\n    const matches = [];\n    for (const text of texts) {\n        const regex = new RegExp(pattern, 'g');\n        const found = text.match(regex);\n        if (found) {\n            matches.push(...found);\n        }\n    }\n    return matches;\n}", "output": "This function is CPU-bound due to regex matching. Looping over large collections and performing expensive regex matches can impact memory usage and slow down performance. Consider using alternative methods for matching or optimizing regex evaluation."}
{"input": "function calculateDistances(points) {\n    const distances = [];\n    for (let i = 0; i < points.length; i++) {\n        for (let j = i + 1; j < points.length; j++) {\n            const dx = points[i].x - points[j].x;\n            const dy = points[i].y - points[j].y;\n            const distance = Math.sqrt(dx * dx + dy * dy);\n            distances.push(distance);\n        }\n    }\n    return distances;\n}", "output": "This function is CPU-bound due to computation-heavy square root calculation and nested looping. Input data should be filtered or sorted to improve functionality."}
{"input": "async function fetchDataSequentially(urls) {\n    const results = [];\n    for (const url of urls) {\n        const response = await fetch(url);\n        const data = await response.json();\n        results.push(data);\n    }\n    return results;\n}", "output": "This function is IO-bound due to fetching data from multiple URLs asynchronously. Async/await usage helps avoid blocking threads during IO operations. However, fetching data sequentially may impact performance due to slow network connections or slow response times from remote servers. Consider using promises or other async/await-friendly ways to fetch data concurrently."}
{"input": "function parseJsonStringsSlowly(jsonStrings) {\n    const results = [];\n    for (const jsonString of jsonStrings) {\n        try {\n            const parsed = JSON.parse(jsonString);\n            results.push(parsed);\n        } catch (error) {\n            console.error('Parse error:', error);\n        }\n    }\n    return results;\n}", "output": "This function is IO-bound due to parsing JSON strings. Async/await usage helps avoid blocking threads during IO operations. Consider using JSON.parse() method for better performance."}
{"input": "function findCommonElements(arrays) {\n    if (arrays.length === 0) return [];\n    \n    let common = arrays[0];\n    for (let i = 1; i < arrays.length; i++) {\n        const newCommon = [];\n        for (const item of common) {\n            if (arrays[i].includes(item)) {\n                newCommon.push(item);\n            }\n        }\n        common = newCommon;\n    }\n    return common;\n}", "output": "This function is CPU-bound due to computation-heavy array intersection. Input validation should be added, and the function could be optimized using sets or other data structures more suited to performing intersections."}
{"input": "function aggregateDataInefficiently(records) {\n    const groups = {};\n    \n    for (const record of records) {\n        if (!groups[record.category]) {\n            groups[record.category] = [];\n        }\n        groups[record.category].push(record);\n    }\n    \n    const aggregated = {};\n    for (const category in groups) {\n        let sum = 0;\n        let count = 0;\n        \n        for (const record of groups[category]) {\n            sum += record.value;\n            count++;\n        }\n        \n        aggregated[category] = {\n            sum: sum,\n            count: count,\n            average: sum / count\n        };\n    }\n    \n    return aggregated;\n}", "output": "This function is CPU-bound due to computation-heavy looping and should be optimized using square brackets or other more efficient ways to group data."}
{"input": "function processLargeDataset(data) {\n    // Multiple inefficient operations on the same dataset\n    const filtered = data.filter(item => item.value > 100);\n    const sorted = data.sort((a, b) => a.value - b.value);\n    const mapped = data.map(item => ({ ...item, processed: true }));\n    const reduced = data.reduce((acc, item) => acc + item.value, 0);\n    \n    return { filtered, sorted, mapped, total: reduced };\n}", "output": "This function is CPU-bound due to filtering, sorting, mapping, and reducing large datasets. Input data should be filtered early and sorted efficiently before mapping and reducing. Consider using LINQ queries or other more efficient ways to process data."}
{"input": "function updateDOMInefficiently(items) {\n    const container = document.getElementById('container');\n    for (const item of items) {\n        const div = document.createElement('div');\n        div.textContent = item;\n        container.appendChild(div);\n        \n        // Force layout recalculation\n        const height = container.offsetHeight;\n    }\n}", "output": "This function is CPU-bound due to DOM manipulation. Avoiding nested loops and forcing layout recalculation can improve performance."}
{"input": "function searchNestedObjects(objects, searchValue) {\n    const results = [];\n    \n    function searchRecursive(obj) {\n        if (typeof obj === 'object' && obj !== null) {\n            for (const key in obj) {\n                if (obj[key] === searchValue) {\n                    results.push(obj);\n                } else if (typeof obj[key] === 'object') {\n                    searchRecursive(obj[key]);\n                }\n            }\n        }\n    }\n    \n    for (const obj of objects) {\n        searchRecursive(obj);\n    }\n    \n    return results;\n}", "output": "This function is recursive and deep. Avoid using recursion heavily due to stack overflow risks. Consider using iteration or other more efficient ways to traverse data structures."}
{"input": "function validateEmailsSlowly(emails) {\n    const validEmails = [];\n    const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    \n    for (const email of emails) {\n        if (emailRegex.test(email)) {\n            validEmails.push(email);\n        }\n    }\n    \n    return validEmails;\n}", "output": "This function is IO-bound due to email validation. Regex testing could be optimized using alternative methods or functions. Consider using functions or methods that are more efficient for performing regular expression matching."}
{"input": "function groupDataInefficiently(data, groupBy) {\n    const groups = {};\n    \n    for (const item of data) {\n        const key = item[groupBy];\n        if (!groups[key]) {\n            groups[key] = [];\n        }\n        groups[key].push(item);\n    }\n    \n    // Sort each group separately (inefficient)\n    for (const key in groups) {\n        groups[key] = groups[key].sort((a, b) => a.value - b.value);\n    }\n    \n    return groups;\n}", "output": "This function is CPU-bound due to sorting large arrays. Input data should be grouped before sorting to improve efficiency."}
{"input": "function calculateStatisticsInMultiplePasses(numbers) {\n    const sum = numbers.reduce((a, b) => a + b, 0);\n    const mean = sum / numbers.length;\n    \n    let variance = 0;\n    for (const num of numbers) {\n        variance += Math.pow(num - mean, 2);\n    }\n    variance /= numbers.length;\n    \n    const sorted = numbers.slice().sort((a, b) => a - b);\n    const median = sorted[Math.floor(sorted.length / 2)];\n    \n    return { mean, variance, median };\n}", "output": "This function is CPU-bound due to computation-heavy reduce() and sort() functions. Input validation should be added, and functionality could be optimized using square root calculation or other more efficient methods for calculating variance."}
{"input": "public class MemoryLeakProne\n{\n    private static List<byte[]> _cache = new List<byte[]>();\n    \n    public void ProcessData(byte[] data)\n    {\n        _cache.Add(data);\n        // Never removes old data, causing memory leak\n        ProcessInternal(data);\n    }\n}", "output": "This code is memory-leaky due to the lack of cache clearing mechanism. Consider implementing cache expiration policies or using more efficient data structures."}
{"input": "def inefficient_data_processing(large_dataset):\n    # Multiple passes through large dataset\n    filtered = [item for item in large_dataset if item['status'] == 'active']\n    sorted_data = sorted(large_dataset, key=lambda x: x['priority'])\n    counted = len([item for item in large_dataset if item['type'] == 'urgent'])\n    return filtered, sorted_data, counted", "output": "This function is inefficient due to its slow performance when processing large datasets. Avoid using nested loops and consider using filters, sorting, and other more efficient ways to process data."}
{"input": "function inefficientDOMUpdates(data) {\n    const container = document.getElementById('list');\n    container.innerHTML = ''; // Clear existing content\n    \n    for (const item of data) {\n        const element = document.createElement('div');\n        element.innerHTML = `<span>${item.name}</span><button onclick='delete(${item.id})'>Delete</button>`;\n        container.appendChild(element);\n        // Triggers layout recalculation for each append\n    }\n}", "output": "This function is inefficient due to the clear method being called on every iteration of the loop. Additionally, appending elements to a container triggers layout recalculations, which impacts performance. Consider using array methods or other more efficient ways to update DOM elements."}
{"input": "public class InMemoryProcessor\n{\n    public List<ProcessedItem> ProcessAllAtOnce(IEnumerable<RawItem> items)\n    {\n        var allItems = items.ToList(); // Load everything into memory\n        var processed = new List<ProcessedItem>();\n        \n        foreach (var item in allItems)\n        {\n            processed.Add(new ProcessedItem(item));\n        }\n        \n        return processed;\n    }\n}", "output": "This method is CPU-bound due to computation-heavy foreach loop. Loading entire collection into memory may impact memory usage and performance during processing large datasets. Consider using LINQ's Concat method or other more efficient ways to concatenate collections."}
{"input": "def slow_text_processing(text_files):\n    all_words = []\n    for file_path in text_files:\n        with open(file_path, 'r') as f:\n            content = f.read()\n            words = content.split()\n            for word in words:\n                if word not in all_words:  # O(n) lookup each time\n                    all_words.append(word)\n    return all_words", "output": "This function is IO-bound due to file reading. Splitting content into words for lookup could benefit from using sets or other data structures more efficient for storing unique values."}
{"input": "function expensiveOperationInLoop(items) {\n    const results = [];\n    for (const item of items) {\n        // Expensive DOM query in each iteration\n        const element = document.querySelector(`[data-id='${item.id}']`);\n        if (element) {\n            results.push({\n                item: item,\n                element: element,\n                computed: window.getComputedStyle(element)\n            });\n        }\n    }\n    return results;\n}", "output": "This function is IO-bound due to DOM querying. Async/await usage helps avoid blocking threads during IO operations. Consider caching frequently queried elements to improve performance."}
{"input": "public class OptimizedStringBuilder\n{\n    public string ConcatenateStrings(List<string> items)\n    {\n        var sb = new StringBuilder();\n        foreach (var item in items)\n        {\n            sb.Append(item);\n        }\n        return sb.ToString();\n    }\n}", "output": "This method is CPU-bound due to string concatenation. While this functionality is clear, performance could be improved using LINQ's Concat method or other more efficient ways to concatenate collections."}
{"input": "public class EfficientDatabaseQuery\n{\n    public List<User> GetActiveUsers()\n    {\n        return context.Users.Where(u => u.IsActive).ToList();\n    }\n}", "output": "This LINQ query is efficient but may benefit from caching frequently requested data. Consider adding additional filters or using LINQ methods such as Contains or Any to improve readability."}
{"input": "public class OptimizedSearch\n{\n    public bool HasCommonElements(int[] array1, int[] array2)\n    {\n        var set2 = new HashSet<int>(array2);\n        return array1.Any(item => set2.Contains(item));\n    }\n}", "output": "This method is CPU-bound due to computation-heavy set intersection. Async/await usage could improve responsiveness, but additional caching or filtering may further optimize performance."}
{"input": "public class StreamProcessor\n{\n    public void ProcessLargeFile(string filePath)\n    {\n        using var reader = new StreamReader(filePath);\n        string line;\n        while ((line = reader.ReadLine()) != null)\n        {\n            ProcessLine(line);\n        }\n    }\n    private void ProcessLine(string line) { /* processing */ }\n}", "output": "This method is IO-bound due to file reading. Async/await usage helps avoid blocking threads during IO operations."}
{"input": "public class EfficientCollectionManager\n{\n    private HashSet<string> _items = new HashSet<string>();\n    \n    public void AddUniqueItem(string newItem)\n    {\n        _items.Add(newItem);\n    }\n    \n    public bool Contains(string item)\n    {\n        return _items.Contains(item);\n    }\n}", "output": "This code is efficient for adding unique items to a hash set but may benefit from using LINQ's Concat method or other more efficient ways to concatenate collections."}
{"input": "def efficient_string_join(items):\n    return ','.join(str(item) for item in items)", "output": "This function is CPU-bound due to string joining. Async/await usage could improve responsiveness, but also introduce additional async/await calls. Consider using alternative data structures or methods for more efficient string concatenation."}
{"input": "def find_duplicates_efficient(list1, list2):\n    set2 = set(list2)\n    return [item for item in list1 if item in set2]", "output": "This function is CPU-bound due to set creation and iteration. Input validation should be added."}
{"input": "def read_large_file_efficiently(filename):\n    with open(filename, 'r') as f:\n        for line in f:\n            line = line.strip()\n            if line:\n                yield line", "output": "This function is IO-bound due to file reading. Async/await usage helps avoid blocking threads during IO operations."}
{"input": "def fibonacci_memoized():\n    cache = {0: 0, 1: 1}\n    def fib(n):\n        if n not in cache:\n            cache[n] = fib(n-1) + fib(n-2)\n        return cache[n]\n    return fib", "output": "This recursive function is CPU-bound due to computation-heavy Fibonacci sequence calculation. Memoization helps avoid computation redundancy, but deep recursion still impacts memory usage and stack depth. Performance can be improved using iterative methods or Fibonacci function square root method."}
{"input": "function efficientStringJoin(items) {\n    return items.join(',');\n}", "output": "Efficient string joining, but may benefit from schema-based typing or other ways to avoid parsing large arrays."}
{"input": "function findIntersectionEfficient(arr1, arr2) {\n    const set2 = new Set(arr2);\n    return arr1.filter(item => set2.has(item));\n}", "output": "Efficient filter method; would benefit from using sets or other data structures more efficient at performing contains operations."}
{"input": "function removeDuplicatesEfficient(arr) {\n    return [...new Set(arr)];\n}", "output": "This function is CPU-bound due to set creation and iteration. Input validation should be added."}
{"input": "async function fetchDataInParallel(urls) {\n    const promises = urls.map(url => fetch(url).then(response => response.json()));\n    return await Promise.all(promises);\n}", "output": "This function is IO-bound due to fetching data from multiple URLs. Async/await usage helps avoid blocking threads during IO operations. While this function is efficient for fetching data in parallel, consider using data caching or other mechanisms to improve efficiency to avoid unnecessary IO."}
